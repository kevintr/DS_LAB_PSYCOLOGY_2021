{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Progetto Data Science Lab\n",
    "## Sentiment Analysis Corona Virus\n",
    "## Giacomo De Cobbi\n",
    "## Alessandro Pontini\n",
    "## Kevin Tranchina"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\tranchinake\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import nltk\n",
    "import re ##regulare expression\n",
    "import string\n",
    "from nltk.tokenize import BlanklineTokenizer\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.tokenize import MWETokenizer\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "import matplotlib.pyplot as plt\n",
    "import subprocess\n",
    "import operator\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "nltk.download('vader_lexicon')\n",
    "sid = SentimentIntensityAnalyzer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<subprocess.Popen at 0x242186a5ec8>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subprocess.Popen(r'explorer /select,\"C:\\Users\\tranchinake\\Desktop\\DataScienceUniversity\\LabBusinessAnalytic\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import and Preprocessing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imposta il path dove vuoi hai i dati\n",
    "\n",
    "path = str(r'C:\\Users\\tranchinake\\Desktop\\DataScienceUniversity\\LabBusinessAnalytic')\n",
    "path = path.replace(\"\\\\\",\"/\")\n",
    "os.chdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lettura file \n",
    "# 33716 righe\n",
    "vaccination = pd.read_csv(\"vaccination_all_tweets.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Same folks said daikon paste could treat a cytokine storm #PfizerBioNTech https://t.co/xeHhIMg1kF'"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vaccination.loc[0,'text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessiong\n",
    "### Rimozione Hash, rimozione Totale tag e link\n",
    "#### Esempio con \n",
    "'Ciao mi chiamo @Antionio Antonio #Ciao #Home @Nicole https://facebook.com'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ciao mi chiamo  Antonio Ciao Home  '"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "esempio = 'Ciao mi chiamo @Antionio Antonio #Ciao #Home @Nicole https://facebook.com'\n",
    "''.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\",\"\",esempio))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Applicazione al nosto dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Same folks said daikon paste could treat a cytokine storm PfizerBioNTech \n",
      "While the world has been on the wrong side of history this year hopefully the biggest vaccination effort weve ev \n",
      "coronavirus SputnikV AstraZeneca PfizerBioNTech Moderna Covid19 Russian vaccine is created to last 24 years \n",
      "Facts are immutable Senator even when youre not ethically sturdy enough to acknowledge them 1 You were born i \n",
      "Explain to me again why we need a vaccine   whereareallthesickpeople PfizerBioNTech \n",
      "Does anyone have any useful adviceguidance for whether the COVID vaccine is safe whilst breastfeeding \n",
      "it is a bit sad to claim the fame for success of vaccination on patriotic competition between USA Canada UK and \n",
      "There have not been many bright days in 2020 but here are some of the best 1 BidenHarris winning Election2020 \n",
      "Covid vaccine You getting it CovidVaccine covid19 PfizerBioNTech Moderna\n",
      "CovidVaccine States will start getting COVID19Vaccine Monday US says pakustv NYC Healthcare GlobalGoals \n",
      "while deaths are closing in on the 300000 mark millions of people wait PfizerBioNTech Vaccine The first U \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0     None\n",
       "1     None\n",
       "2     None\n",
       "3     None\n",
       "4     None\n",
       "5     None\n",
       "6     None\n",
       "7     None\n",
       "8     None\n",
       "9     None\n",
       "10    None\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rimozione del cancelletto nell'hashtag \n",
    "# rimozione dei link e dei tag\n",
    "vaccination.loc[:,'text'] = vaccination.loc[:,'text'].apply(lambda x : ''.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\",\"\",x)))\n",
    "vaccination.loc[0:10,'text'].apply(lambda x : print(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "## lowerCase\n",
    "# vaccination.text = vaccination.text.str.lower()\n",
    "\n",
    "## rimozione dei numeri\n",
    "vaccination.text = vaccination.text.replace(r'\\d+','')\n",
    "\n",
    "## rimozione spazi bianchi\n",
    "vaccination.text  = vaccination.text.astype(str).str.strip()\n",
    "\n",
    "# rimozione punteggiatura\n",
    "# verificato rimuove anche i cancelletti\n",
    "vaccination.text=vaccination.text.astype(str).str.translate(str.maketrans('','',string.punctuation))\n",
    "\n",
    "#rimozione \\n\n",
    "vaccination.text = vaccination.text.replace(\"\\n\",\" \")\n",
    "\n",
    "#rimozione apice strano\n",
    "vaccination.text = vaccination.text.replace(\"'â€™'\",\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [Same, folks, said, daikon, paste, could, trea...\n",
       "1        [While, the, world, has, been, on, the, wrong,...\n",
       "2        [#coronavirus, #SputnikV, #AstraZeneca, #Pfize...\n",
       "3        [Facts, are, immutable, ,, Senator, ,, even, w...\n",
       "4        [Explain, to, me, again, why, we, need, a, vac...\n",
       "                               ...                        \n",
       "33712    [#BREAKING, The, information, attack, targetin...\n",
       "33713    [Pity, ,, as, my, personal, preference, would,...\n",
       "33714    [#WHO, in, close, contact, with, #Russia, on, ...\n",
       "33715    [#URGENT, |, US, targets, Europe, in, smear, c...\n",
       "33716    [#BREAKING, #US, Targets, Europe, in, Smear, C...\n",
       "Name: tweet_tokenize, Length: 33717, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TweetTokenizer\n",
    "tknzr = TweetTokenizer()\n",
    "vaccination['tweet_tokenize'] = vaccination['text'].apply(tknzr.tokenize)\n",
    "vaccination['tweet_tokenize']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\tranchinake\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0        [folks, said, daikon, paste, could, treat, cyt...\n",
       "1        [world, wrong, side, history, year, hopefully,...\n",
       "2        [coronavirus, sputnikv, astrazeneca, pfizerbio...\n",
       "3        [facts, immutable, senator, even, ethically, s...\n",
       "4        [explain, need, vaccine, borisjohnson, matthan...\n",
       "                               ...                        \n",
       "33712    [breaking, information, attack, targeting, spu...\n",
       "33713    [pity, personal, preference, would, astrazenec...\n",
       "33714    [close, contact, russia, sputnikv, certificati...\n",
       "33715    [urgent, us, targets, europe, smear, campaign,...\n",
       "33716    [breaking, us, targets, europe, smear, campaig...\n",
       "Name: tweet_without_stopwords, Length: 33717, dtype: object"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rimozione Stop Words\n",
    "nltk.download('stopwords')\n",
    "stop_words = nltk.corpus.stopwords.words('english')\n",
    "stop_words += ['im','youre','thats','get','cant','dont','go',\n",
    "               'going','gonna','like','got', 'come', 'look','see','theres',\n",
    "               'say','want','wanna','make','yes','right','']\n",
    "\n",
    "\n",
    "vaccination['tweet_without_stopwords'] = vaccination['tweet_tokenize'].apply(lambda x: [item for item in x if item not in stop_words])\n",
    "vaccination['tweet_without_stopwords'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis\n",
    "## VADER ( Valence Aware Dictionary for Sentiment Reasoning)\n",
    "#### VADER  is a model used for text sentiment analysis that is sensitive to both polarity (positive/negative) and intensity (strength) of emotion. It is available in the NLTK package and can be applied directly to unlabeled text data.\n",
    "\n",
    "#### To calculate the sentimental score of the entire text, Vader scans the text for known sentimental features, modified the intensity and polarity according to the rules, summed up the scores of features found within the text and normalized the final score to (-1, 1) using function:\n",
    "\n",
    "\n",
    "\n",
    "$$ compound=\\frac{x}{\\sqrt{x^2 +a}}$$\n",
    "\n",
    " \n",
    "\n",
    "#### In Vader, alpha is set to be 15 which approximates the maximum expected value of x."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "vaccination['scores']  = vaccination['text'] .apply(lambda review: sid.polarity_scores(review))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        {'neg': 0.0, 'neu': 0.787, 'pos': 0.213, 'comp...\n",
       "1        {'neg': 0.125, 'neu': 0.766, 'pos': 0.109, 'co...\n",
       "2        {'neg': 0.0, 'neu': 0.875, 'pos': 0.125, 'comp...\n",
       "3        {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...\n",
       "4        {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...\n",
       "                               ...                        \n",
       "33712    {'neg': 0.162, 'neu': 0.838, 'pos': 0.0, 'comp...\n",
       "33713    {'neg': 0.086, 'neu': 0.914, 'pos': 0.0, 'comp...\n",
       "33714    {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...\n",
       "33715    {'neg': 0.139, 'neu': 0.721, 'pos': 0.14, 'com...\n",
       "33716    {'neg': 0.152, 'neu': 0.848, 'pos': 0.0, 'comp...\n",
       "Name: scores, Length: 33717, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vaccination['scores']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'neg': 0.0, 'neu': 0.323, 'pos': 0.677, 'compound': 0.6369}\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "a = 'I love my girl'\n",
    "print(sid.polarity_scores(a))\n",
    "\n",
    "#-0,5<x<+0.5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0.4019\n",
       "1       -0.1027\n",
       "2        0.2500\n",
       "3        0.0000\n",
       "4        0.0000\n",
       "          ...  \n",
       "33712   -0.4767\n",
       "33713   -0.1531\n",
       "33714    0.0000\n",
       "33715    0.0085\n",
       "33716   -0.3612\n",
       "Name: compound, Length: 33717, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vaccination['compound']  = vaccination['scores'].apply(lambda score_dict: score_dict['compound'])\n",
    "vaccination['compound']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aggregazioni e analisi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'user_name', 'user_location', 'user_description', 'user_created',\n",
      "       'user_followers', 'user_friends', 'user_favourites', 'user_verified',\n",
      "       'date', 'text', 'hashtags', 'source', 'retweets', 'favorites',\n",
      "       'is_retweet'],\n",
      "      dtype='object')\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 33717 entries, 0 to 33716\n",
      "Data columns (total 16 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   id                33717 non-null  int64 \n",
      " 1   user_name         33717 non-null  object\n",
      " 2   user_location     25937 non-null  object\n",
      " 3   user_description  31402 non-null  object\n",
      " 4   user_created      33717 non-null  object\n",
      " 5   user_followers    33717 non-null  int64 \n",
      " 6   user_friends      33717 non-null  int64 \n",
      " 7   user_favourites   33717 non-null  int64 \n",
      " 8   user_verified     33717 non-null  bool  \n",
      " 9   date              33717 non-null  object\n",
      " 10  text              33717 non-null  object\n",
      " 11  hashtags          26543 non-null  object\n",
      " 12  source            33689 non-null  object\n",
      " 13  retweets          33717 non-null  int64 \n",
      " 14  favorites         33717 non-null  int64 \n",
      " 15  is_retweet        33717 non-null  bool  \n",
      "dtypes: bool(2), int64(6), object(8)\n",
      "memory usage: 3.7+ MB\n",
      "None\n",
      "\n",
      "Describe\n",
      "\n",
      "count     25937\n",
      "unique     7259\n",
      "top       India\n",
      "freq        988\n",
      "Name: user_location, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(vaccination.columns)\n",
    "print(vaccination.info())\n",
    "print('\\nDescribe\\n')\n",
    "print(vaccination['user_location'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 25937 entries, 0 to 33716\n",
      "Data columns (total 16 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   id                25937 non-null  int64 \n",
      " 1   user_name         25937 non-null  object\n",
      " 2   user_location     25937 non-null  object\n",
      " 3   user_description  24970 non-null  object\n",
      " 4   user_created      25937 non-null  object\n",
      " 5   user_followers    25937 non-null  int64 \n",
      " 6   user_friends      25937 non-null  int64 \n",
      " 7   user_favourites   25937 non-null  int64 \n",
      " 8   user_verified     25937 non-null  bool  \n",
      " 9   date              25937 non-null  object\n",
      " 10  text              25937 non-null  object\n",
      " 11  hashtags          20371 non-null  object\n",
      " 12  source            25929 non-null  object\n",
      " 13  retweets          25937 non-null  int64 \n",
      " 14  favorites         25937 non-null  int64 \n",
      " 15  is_retweet        25937 non-null  bool  \n",
      "dtypes: bool(2), int64(6), object(8)\n",
      "memory usage: 3.0+ MB\n"
     ]
    }
   ],
   "source": [
    "vaccination = vaccination[vaccination['user_location'].notna()]\n",
    "#vaccination['user_location2'] = vaccination['user_location'].dropna()\n",
    "vaccination.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Same folks said daikon paste could treat a cytokine storm PfizerBioNTech httpstcoxeHhIMg1kF'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vaccination.loc[vaccination['user_location'].str.contains('Italy', regex=True, na=False)]\n",
    "vaccination.loc[0,'text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                       ['PfizerBioNTech']\n",
       "1                                                      NaN\n",
       "2        ['coronavirus', 'SputnikV', 'AstraZeneca', 'Pf...\n",
       "3                                                      NaN\n",
       "4           ['whereareallthesickpeople', 'PfizerBioNTech']\n",
       "                               ...                        \n",
       "33712                       ['BREAKING', 'SputnikV', 'US']\n",
       "33713                 ['AstraZeneca', 'vaccine', 'Pfizer']\n",
       "33714                        ['WHO', 'Russia', 'SputnikV']\n",
       "33715                                           ['URGENT']\n",
       "33716             ['BREAKING', 'US', 'Russia', 'SputnikV']\n",
       "Name: hashtags, Length: 33717, dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vaccination['hashtags']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

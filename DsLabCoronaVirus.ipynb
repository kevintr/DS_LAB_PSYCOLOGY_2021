{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Progetto Data Science Lab\n",
    "## Sentiment Analysis Corona Virus\n",
    "## Giacomo De Cobbi\n",
    "## Alessandro Pontini\n",
    "## Kevin Tranchina"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\tranchinake\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import nltk\n",
    "import re ##regulare expression\n",
    "import string\n",
    "from nltk.tokenize import BlanklineTokenizer\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.tokenize import MWETokenizer\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "import matplotlib.pyplot as plt\n",
    "import subprocess\n",
    "import operator\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "nltk.download('vader_lexicon')\n",
    "sid = SentimentIntensityAnalyzer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<subprocess.Popen at 0x194195b4e88>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subprocess.Popen(r'explorer /select,\"C:\\Users\\tranchinake\\Desktop\\DataScienceUniversity\\LabBusinessAnalytic\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import and Preprocessing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imposta il path dove vuoi hai i dati\n",
    "\n",
    "path = str(r'C:\\Users\\tranchinake\\Desktop\\DataScienceUniversity\\LabBusinessAnalytic')\n",
    "path = path.replace(\"\\\\\",\"/\")\n",
    "os.chdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lettura file \n",
    "# 33716 righe\n",
    "vaccination = pd.read_csv(\"vaccination_all_tweets.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Same folks said daikon paste could treat a cytokine storm #PfizerBioNTech https://t.co/xeHhIMg1kF'"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vaccination.loc[0,'text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessiong\n",
    "### Rimozione Hash, rimozione di tutto i tag e i link\n",
    "#### Esempio con \n",
    "'Ciao mi chiamo @Antionio Antonio #Ciao #Home @Nicole https://facebook.com'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ciao mi chiamo @Giuseppe Antonio #Ciao #Home @Nicole https://facebook.com\n",
      "Ciao mi chiamo  Antonio Ciao Home  \n",
      "Ciao mi chiamo Antonio Ciao Home \n"
     ]
    }
   ],
   "source": [
    "esempio = 'Ciao mi chiamo @Giuseppe Antonio #Ciao #Home @Nicole https://facebook.com'\n",
    "print(esempio)\n",
    "# @[A-Za-z0-9]+ rimuove tutte le parole(caratteri alfanumerici) che cominciano con @\n",
    "# #[A-Za-z0-9]+ rimuove tutte le parole(caratteri alfanumerici) che cominciano con #\n",
    "# [^0-9A-Za-z ] tiene solo i caratteri alfanumerici\n",
    "# (\\w+:\\/\\/\\S+) rimozione link\n",
    "\n",
    "esempio = re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z ])|(\\w+:\\/\\/\\S+)\",\"\",esempio)\n",
    "\n",
    "# fa la stessa cosa di sopra, ma più pulito\n",
    "# esempio = re.sub(\"(@\\w+)| (#\\w+)|([^\\w ])|(\\w+:\\/\\/\\S+)\",\"\",esempio)\n",
    "\n",
    "print(esempio)\n",
    "\n",
    "\n",
    "# Rimuove anche gli hashtag interi\n",
    "# esempio = re.sub(\"(@[A-Za-z0-9]+)| (#[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\",\"\",esempio)\n",
    "\n",
    "# Rimozione degli spazi in più\n",
    "esempio = re.sub(' +',' ',esempio)\n",
    "print(esempio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Applicazione al nosto dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Same folks said daikon paste could treat a cytokine storm \n",
      "While the world has been on the wrong side of history this year hopefully the biggest vaccination effort weve ev \n",
      "coronavirus19 Russian vaccine is created to last 24 years \n",
      "Facts are immutable Senator even when youre not ethically sturdy enough to acknowledge them 1 You were born i \n",
      "Explain to me again why we need a vaccine   \n",
      "Does anyone have any useful adviceguidance for whether the COVID vaccine is safe whilst breastfeeding \n",
      "it is a bit sad to claim the fame for success of on patriotic competition between USA Canada UK and \n",
      "There have not been many bright days in 2020 but here are some of the best 1 winning \n",
      "Covid vaccine You getting it\n",
      "CovidVaccine States will start getting Monday says pakustv \n",
      "while deaths are closing in on the 300000 mark millions of people wait The first U \n"
     ]
    }
   ],
   "source": [
    "# rimozione del cancelletto nell'hashtag \n",
    "# rimozione dei link e dei tag\n",
    "\n",
    "reNoHashNoTagNoLink = \"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\"\n",
    "reNo_HashTAG_NoTagNoLink = \"(@[A-Za-z0-9]+)| (#[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\"\n",
    "vaccination.loc[:,'text'] = vaccination.loc[:,'text'].apply(lambda x : ''.join(re.sub(reNo_HashTAG_NoTagNoLink,\"\",x)))\n",
    "stampa = vaccination.loc[0:10,'text'].apply(lambda x : print(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        Same folks said daikon paste could treat a cyt...\n",
       "1        While the world has been on the wrong side of ...\n",
       "2        coronavirus19 Russian vaccine is created to la...\n",
       "3        Facts are immutable Senator even when youre no...\n",
       "4                Explain to me again why we need a vaccine\n",
       "                               ...                        \n",
       "33712    BREAKING The information attack targeting will...\n",
       "33713    Pity as my personal preference would have been...\n",
       "33714           WHO in close contact with on certification\n",
       "33715    URGENT US targets Europe in smear campaign aga...\n",
       "33716    BREAKING US Targets Europe in Smear Campaign A...\n",
       "Name: text, Length: 33717, dtype: object"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## lowerCase\n",
    "# vaccination.text = vaccination.text.str.lower()\n",
    "\n",
    "## rimozione dei numeri\n",
    "vaccination.text = vaccination.text.replace(r'\\d+','')\n",
    "\n",
    "## rimozione spazi bianchi\n",
    "vaccination.text  = vaccination.text.astype(str).str.strip()\n",
    "\n",
    "## rimozione doppi spazi bianchi\n",
    "vaccination.text = vaccination.text.replace(' +',' ', regex=True)\n",
    "\n",
    "# rimozione punteggiatura\n",
    "# verificato rimuove anche i cancelletti\n",
    "vaccination.text=vaccination.text.astype(str).str.translate(str.maketrans('','',string.punctuation))\n",
    "\n",
    "#rimozione \\n\n",
    "vaccination.text = vaccination.text.replace(\"\\n\",\" \")\n",
    "\n",
    "#rimozione apice strano\n",
    "vaccination.text = vaccination.text.replace(\"'’'\",\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [Same, folks, said, daikon, paste, could, trea...\n",
       "1        [While, the, world, has, been, on, the, wrong,...\n",
       "2        [coronavirus, SputnikV, AstraZeneca, PfizerBio...\n",
       "3        [Facts, are, immutable, Senator, even, when, y...\n",
       "4        [Explain, to, me, again, why, we, need, a, vac...\n",
       "                               ...                        \n",
       "33712    [BREAKING, The, information, attack, targeting...\n",
       "33713    [Pity, as, my, personal, preference, would, ha...\n",
       "33714    [WHO, in, close, contact, with, Russia, on, Sp...\n",
       "33715    [URGENT, US, targets, Europe, in, smear, campa...\n",
       "33716    [BREAKING, US, Targets, Europe, in, Smear, Cam...\n",
       "Name: tweet_tokenize, Length: 33717, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TweetTokenizer\n",
    "tknzr = TweetTokenizer()\n",
    "vaccination['tweet_tokenize'] = vaccination['text'].apply(tknzr.tokenize)\n",
    "vaccination['tweet_tokenize']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\tranchinake\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0        [Same, folks, said, daikon, paste, could, trea...\n",
       "1        [While, world, wrong, side, history, year, hop...\n",
       "2        [coronavirus, SputnikV, AstraZeneca, PfizerBio...\n",
       "3        [Facts, immutable, Senator, even, ethically, s...\n",
       "4        [Explain, need, vaccine, whereareallthesickpeo...\n",
       "                               ...                        \n",
       "33712    [BREAKING, The, information, attack, targeting...\n",
       "33713    [Pity, personal, preference, would, AstraZenec...\n",
       "33714    [WHO, close, contact, Russia, SputnikV, certif...\n",
       "33715    [URGENT, US, targets, Europe, smear, campaign,...\n",
       "33716    [BREAKING, US, Targets, Europe, Smear, Campaig...\n",
       "Name: tweet_without_stopwords, Length: 33717, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rimozione Stop Words\n",
    "nltk.download('stopwords')\n",
    "stop_words = nltk.corpus.stopwords.words('english')\n",
    "stop_words += ['im','youre','thats','get','cant','dont','go',\n",
    "               'going','gonna','like','got', 'come', 'look','see','theres',\n",
    "               'say','want','wanna','make','yes','right','']\n",
    "\n",
    "\n",
    "vaccination['tweet_without_stopwords'] = vaccination['tweet_tokenize'].apply(lambda x: [item for item in x if item not in stop_words])\n",
    "vaccination['tweet_without_stopwords'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis\n",
    "## VADER ( Valence Aware Dictionary for Sentiment Reasoning)\n",
    "#### VADER  is a model used for text sentiment analysis that is sensitive to both polarity (positive/negative) and intensity (strength) of emotion. It is available in the NLTK package and can be applied directly to unlabeled text data.\n",
    "\n",
    "#### To calculate the sentimental score of the entire text, Vader scans the text for known sentimental features, modified the intensity and polarity according to the rules, summed up the scores of features found within the text and normalized the final score to (-1, 1) using function:\n",
    "\n",
    "\n",
    "\n",
    "$$ compound=\\frac{x}{\\sqrt{x^2 +a}}$$\n",
    "\n",
    " \n",
    "\n",
    "#### In Vader, alpha is set to be 15 which approximates the maximum expected value of x."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "vaccination['scores']  = vaccination['text'] .apply(lambda review: sid.polarity_scores(review))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        {'neg': 0.0, 'neu': 0.769, 'pos': 0.231, 'comp...\n",
       "1        {'neg': 0.13, 'neu': 0.756, 'pos': 0.113, 'com...\n",
       "2        {'neg': 0.0, 'neu': 0.867, 'pos': 0.133, 'comp...\n",
       "3        {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...\n",
       "4        {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...\n",
       "                               ...                        \n",
       "33712    {'neg': 0.181, 'neu': 0.819, 'pos': 0.0, 'comp...\n",
       "33713    {'neg': 0.096, 'neu': 0.904, 'pos': 0.0, 'comp...\n",
       "33714    {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...\n",
       "33715    {'neg': 0.147, 'neu': 0.705, 'pos': 0.149, 'co...\n",
       "33716    {'neg': 0.161, 'neu': 0.839, 'pos': 0.0, 'comp...\n",
       "Name: scores, Length: 33717, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vaccination['scores']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'neg': 0.0, 'neu': 0.323, 'pos': 0.677, 'compound': 0.6369}\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "a = 'I love my girl'\n",
    "print(sid.polarity_scores(a))\n",
    "\n",
    "#-0,5<x<+0.5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0.4019\n",
       "1       -0.1027\n",
       "2        0.2500\n",
       "3        0.0000\n",
       "4        0.0000\n",
       "          ...  \n",
       "33712   -0.4767\n",
       "33713   -0.1531\n",
       "33714    0.0000\n",
       "33715    0.0085\n",
       "33716   -0.3612\n",
       "Name: compound, Length: 33717, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vaccination['compound']  = vaccination['scores'].apply(lambda score_dict: score_dict['compound'])\n",
    "vaccination['compound']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aggregazioni e analisi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'user_name', 'user_location', 'user_description', 'user_created',\n",
      "       'user_followers', 'user_friends', 'user_favourites', 'user_verified',\n",
      "       'date', 'text', 'hashtags', 'source', 'retweets', 'favorites',\n",
      "       'is_retweet', 'tweet_tokenize', 'tweet_without_stopwords', 'scores',\n",
      "       'compound'],\n",
      "      dtype='object')\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 33717 entries, 0 to 33716\n",
      "Data columns (total 20 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   id                       33717 non-null  int64  \n",
      " 1   user_name                33717 non-null  object \n",
      " 2   user_location            25937 non-null  object \n",
      " 3   user_description         31402 non-null  object \n",
      " 4   user_created             33717 non-null  object \n",
      " 5   user_followers           33717 non-null  int64  \n",
      " 6   user_friends             33717 non-null  int64  \n",
      " 7   user_favourites          33717 non-null  int64  \n",
      " 8   user_verified            33717 non-null  bool   \n",
      " 9   date                     33717 non-null  object \n",
      " 10  text                     33717 non-null  object \n",
      " 11  hashtags                 26543 non-null  object \n",
      " 12  source                   33689 non-null  object \n",
      " 13  retweets                 33717 non-null  int64  \n",
      " 14  favorites                33717 non-null  int64  \n",
      " 15  is_retweet               33717 non-null  bool   \n",
      " 16  tweet_tokenize           33717 non-null  object \n",
      " 17  tweet_without_stopwords  33717 non-null  object \n",
      " 18  scores                   33717 non-null  object \n",
      " 19  compound                 33717 non-null  float64\n",
      "dtypes: bool(2), float64(1), int64(6), object(11)\n",
      "memory usage: 4.7+ MB\n",
      "None\n",
      "\n",
      "Describe\n",
      "\n",
      "count     25937\n",
      "unique     7259\n",
      "top       India\n",
      "freq        988\n",
      "Name: user_location, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(vaccination.columns)\n",
    "print(vaccination.info())\n",
    "print('\\nDescribe\\n')\n",
    "print(vaccination['user_location'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 25937 entries, 0 to 33716\n",
      "Data columns (total 20 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   id                       25937 non-null  int64  \n",
      " 1   user_name                25937 non-null  object \n",
      " 2   user_location            25937 non-null  object \n",
      " 3   user_description         24970 non-null  object \n",
      " 4   user_created             25937 non-null  object \n",
      " 5   user_followers           25937 non-null  int64  \n",
      " 6   user_friends             25937 non-null  int64  \n",
      " 7   user_favourites          25937 non-null  int64  \n",
      " 8   user_verified            25937 non-null  bool   \n",
      " 9   date                     25937 non-null  object \n",
      " 10  text                     25937 non-null  object \n",
      " 11  hashtags                 20371 non-null  object \n",
      " 12  source                   25929 non-null  object \n",
      " 13  retweets                 25937 non-null  int64  \n",
      " 14  favorites                25937 non-null  int64  \n",
      " 15  is_retweet               25937 non-null  bool   \n",
      " 16  tweet_tokenize           25937 non-null  object \n",
      " 17  tweet_without_stopwords  25937 non-null  object \n",
      " 18  scores                   25937 non-null  object \n",
      " 19  compound                 25937 non-null  float64\n",
      "dtypes: bool(2), float64(1), int64(6), object(11)\n",
      "memory usage: 3.8+ MB\n"
     ]
    }
   ],
   "source": [
    "vaccination = vaccination[vaccination['user_location'].notna()]\n",
    "#vaccination['user_location2'] = vaccination['user_location'].dropna()\n",
    "vaccination.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Same folks said daikon paste could treat a cytokine storm PfizerBioNTech'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vaccination.loc[vaccination['user_location'].str.contains('Italy', regex=True, na=False)]\n",
    "vaccination.loc[0,'text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                       ['PfizerBioNTech']\n",
       "1                                                      NaN\n",
       "2        ['coronavirus', 'SputnikV', 'AstraZeneca', 'Pf...\n",
       "3                                                      NaN\n",
       "5                                                      NaN\n",
       "                               ...                        \n",
       "33708                              ['Zakharova', 'Russia']\n",
       "33712                       ['BREAKING', 'SputnikV', 'US']\n",
       "33713                 ['AstraZeneca', 'vaccine', 'Pfizer']\n",
       "33714                        ['WHO', 'Russia', 'SputnikV']\n",
       "33716             ['BREAKING', 'US', 'Russia', 'SputnikV']\n",
       "Name: hashtags, Length: 25937, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vaccination['hashtags']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
